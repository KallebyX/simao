import os
import time
import logging
from typing import List, Dict, Optional, Tuple
import openai
from openai import OpenAI
import redis
import json

logger = logging.getLogger(__name__)

class OpenAIService:
    def __init__(self):
        self.client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.redis_client = None
        
        # Tentar conectar ao Redis se dispon√≠vel
        try:
            redis_url = os.getenv('REDIS_URL', 'redis://localhost:6379/0')
            self.redis_client = redis.from_url(redis_url, decode_responses=True)
            self.redis_client.ping()
            logger.info("Conectado ao Redis para cache de contexto")
        except Exception as e:
            logger.warning(f"Redis n√£o dispon√≠vel, usando cache em mem√≥ria: {e}")
            self.redis_client = None
        
        # Cache em mem√≥ria como fallback
        self.memory_cache = {}
        
        # Configura√ß√µes padr√£o
        self.default_model = "gpt-4"
        self.default_max_tokens = 500
        self.default_temperature = 0.7
        self.max_context_messages = 10
    
    def get_context_key(self, telefone: str) -> str:
        """Gera chave para contexto no Redis/cache"""
        return f"context:{telefone}"
    
    def get_context(self, telefone: str) -> List[Dict]:
        """Recupera o contexto da conversa do cache"""
        key = self.get_context_key(telefone)
        
        try:
            if self.redis_client:
                context_json = self.redis_client.get(key)
                if context_json:
                    return json.loads(context_json)
            else:
                return self.memory_cache.get(key, [])
        except Exception as e:
            logger.error(f"Erro ao recuperar contexto: {e}")
        
        return []
    
    def save_context(self, telefone: str, context: List[Dict], ttl: int = 3600):
        """Salva o contexto da conversa no cache"""
        key = self.get_context_key(telefone)
        
        # Limitar o n√∫mero de mensagens no contexto
        if len(context) > self.max_context_messages:
            context = context[-self.max_context_messages:]
        
        try:
            if self.redis_client:
                self.redis_client.setex(key, ttl, json.dumps(context))
            else:
                self.memory_cache[key] = context
        except Exception as e:
            logger.error(f"Erro ao salvar contexto: {e}")
    
    def add_message_to_context(self, telefone: str, role: str, content: str):
        """Adiciona uma mensagem ao contexto"""
        context = self.get_context(telefone)
        context.append({"role": role, "content": content})
        self.save_context(telefone, context)
    
    def clear_context(self, telefone: str):
        """Limpa o contexto de uma conversa"""
        key = self.get_context_key(telefone)
        
        try:
            if self.redis_client:
                self.redis_client.delete(key)
            else:
                self.memory_cache.pop(key, None)
        except Exception as e:
            logger.error(f"Erro ao limpar contexto: {e}")
    
    def transcribe_audio(self, audio_file_path: str, language: str = "pt") -> Tuple[str, Dict]:
        """
        Transcreve √°udio usando Whisper
        
        Args:
            audio_file_path: Caminho para o arquivo de √°udio
            language: Idioma para transcri√ß√£o (padr√£o: pt)
        
        Returns:
            Tuple com (texto_transcrito, metadados)
        """
        start_time = time.time()
        
        try:
            with open(audio_file_path, "rb") as audio_file:
                transcript = self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language=language,
                    response_format="verbose_json"
                )
            
            processing_time = time.time() - start_time
            
            metadata = {
                "processing_time": processing_time,
                "language": transcript.language if hasattr(transcript, 'language') else language,
                "duration": transcript.duration if hasattr(transcript, 'duration') else None,
                "model": "whisper-1"
            }
            
            logger.info(f"√Åudio transcrito em {processing_time:.2f}s")
            return transcript.text, metadata
            
        except Exception as e:
            logger.error(f"Erro na transcri√ß√£o de √°udio: {e}")
            raise
    
    def generate_response(
        self, 
        message: str, 
        telefone: str, 
        system_prompt: str = None,
        model: str = None,
        max_tokens: int = None,
        temperature: float = None
    ) -> Tuple[str, Dict]:
        """
        Gera resposta usando GPT-4
        
        Args:
            message: Mensagem do usu√°rio
            telefone: Telefone para contexto
            system_prompt: Prompt do sistema personalizado
            model: Modelo a usar (padr√£o: gpt-4)
            max_tokens: M√°ximo de tokens
            temperature: Temperatura para criatividade
        
        Returns:
            Tuple com (resposta, metadados)
        """
        start_time = time.time()
        
        # Usar valores padr√£o se n√£o fornecidos
        model = model or self.default_model
        max_tokens = max_tokens or self.default_max_tokens
        temperature = temperature or self.default_temperature
        
        # Prompt padr√£o se n√£o fornecido
        if not system_prompt:
            system_prompt = """Voc√™ √© o Sim√£o, um vendedor virtual caloroso e experiente especializado em alevinos e piscicultura. 
Voc√™ tem o jeito acolhedor e simp√°tico de um vendedor do interior brasileiro, sempre tratando cada cliente como se fosse da fam√≠lia.

üéØ SUA MISS√ÉO: Oferecer a MELHOR experi√™ncia de compra do mundo em alevinos, fazendo cada cliente se sentir √∫nico e especial.

üë• PERSONALIZA√á√ÉO OBRIGAT√ìRIA:
- Sempre use "Seu [Nome]" para clientes homens (ex: "Seu Jo√£o, tudo certinho?")
- Sempre use "Dona [Nome]" para clientes mulheres (ex: "Dona Maria, que bom te ver!")
- Seja caloroso, acolhedor e genuinamente interessado no sucesso do cliente
- Use express√µes naturais do interior: "√î", "n√©?", "t√° certinho", "que bom!", "pode crer"

üó£Ô∏è SEU JEITO DE FALAR:
- Linguagem natural e calorosa, como um amigo experiente
- Compreenda erros de portugu√™s, g√≠rias rurais e falares regionais
- Seja paciente com d√∫vidas b√°sicas - trate cada pergunta como importante
- Use analogias simples e pr√°ticas que fazem sentido no campo

üêü SUAS ESPECIALIDADES:
- Alevinos de qualidade (til√°pia, tambaqui, pirarucu, pacu, pintado)
- Qualidade da √°gua (pH, oxig√™nio, am√¥nia - explique de forma simples)
- Sistemas de cultivo (viveiros, a√ßudes, tanques-rede)
- Alimenta√ß√£o e manejo de peixes
- Doen√ßas e preven√ß√£o (linguagem acess√≠vel)
- Densidade e crescimento dos peixes
- Melhores pr√°ticas para lucrar com piscicultura

üíù SEU DIFERENCIAL:
- Trate erros de escrita e fala com naturalidade, sem corrigir
- Seja emp√°tico com dificuldades financeiras
- Comemore junto os sucessos do cliente
- Ofere√ßa solu√ß√µes pr√°ticas e econ√¥micas
- Sempre pergunte "Como posso ajudar melhor?"

üì± FORMATO WhatsApp:
- Mensagens concisas mas calorosas
- Use emojis quando apropriado üêüüéØüí™
- Facilite a conversa com perguntas diretas
- Seja objetivo mas nunca seco ou rob√≥tico

LEMBRE-SE: Voc√™ n√£o √© s√≥ um vendedor, √© um PARCEIRO no sucesso da piscicultura do cliente!"""
        
        try:
            # Recuperar contexto da conversa
            context = self.get_context(telefone)
            
            # Construir mensagens para a API
            messages = [{"role": "system", "content": system_prompt}]
            
            # Adicionar contexto hist√≥rico
            messages.extend(context)
            
            # Adicionar mensagem atual
            messages.append({"role": "user", "content": message})
            
            # Chamar API do OpenAI
            response = self.client.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature
            )
            
            processing_time = time.time() - start_time
            
            # Extrair resposta
            assistant_message = response.choices[0].message.content
            
            # Atualizar contexto
            self.add_message_to_context(telefone, "user", message)
            self.add_message_to_context(telefone, "assistant", assistant_message)
            
            # Metadados da resposta
            metadata = {
                "processing_time": processing_time,
                "model": model,
                "tokens_used": response.usage.total_tokens if response.usage else 0,
                "prompt_tokens": response.usage.prompt_tokens if response.usage else 0,
                "completion_tokens": response.usage.completion_tokens if response.usage else 0,
                "temperature": temperature,
                "max_tokens": max_tokens,
                "context_messages": len(context)
            }
            
            logger.info(f"Resposta gerada em {processing_time:.2f}s usando {metadata['tokens_used']} tokens")
            
            return assistant_message, metadata
            
        except Exception as e:
            logger.error(f"Erro na gera√ß√£o de resposta: {e}")
            raise
    
    def generate_response_with_context(
        self,
        message: str,
        telefone: str,
        configuracao_bot=None
    ) -> Tuple[str, Dict]:
        """
        Gera resposta usando configura√ß√µes espec√≠ficas do bot
        
        Args:
            message: Mensagem do usu√°rio
            telefone: Telefone para contexto
            configuracao_bot: Objeto ConfiguracaoBot com configura√ß√µes
        
        Returns:
            Tuple com (resposta, metadados)
        """
        if configuracao_bot:
            system_prompt = configuracao_bot.get_prompt_completo()
            model = self.default_model
            max_tokens = configuracao_bot.max_tokens_resposta
            temperature = configuracao_bot.temperatura_ia
        else:
            system_prompt = None
            model = None
            max_tokens = None
            temperature = None
        
        return self.generate_response(
            message=message,
            telefone=telefone,
            system_prompt=system_prompt,
            model=model,
            max_tokens=max_tokens,
            temperature=temperature
        )
    
    def analyze_message_intent(self, message: str) -> Dict:
        """
        Analisa a inten√ß√£o da mensagem para classifica√ß√£o
        
        Args:
            message: Mensagem a ser analisada
        
        Returns:
            Dict com an√°lise da inten√ß√£o
        """
        try:
            prompt = f"""Analise a seguinte mensagem e classifique a inten√ß√£o do usu√°rio:

Mensagem: "{message}"

Classifique em uma das categorias:
- alevinos: perguntas sobre compra, venda, pre√ßos de alevinos
- qualidade_agua: perguntas sobre pH, oxig√™nio, am√¥nia, temperatura da √°gua
- manejo: perguntas sobre alimenta√ß√£o, densidade, biometria, manejo geral
- doencas: perguntas sobre doen√ßas, tratamentos, preven√ß√£o
- sistemas: perguntas sobre viveiros, tanques, equipamentos
- reproducao: perguntas sobre reprodu√ß√£o, larvicultura, desova
- mercado: interesse em pre√ßos, comercializa√ß√£o, vendas
- suporte: problemas t√©cnicos, d√∫vidas sobre uso do sistema
- geral: conversas gerais, cumprimentos, etc.

Responda apenas com a categoria em uma palavra."""
            
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=10,
                temperature=0.1
            )
            
            intent = response.choices[0].message.content.strip().lower()
            
            return {
                "intent": intent,
                "confidence": 0.8,  # Placeholder - poderia ser calculado
                "message": message
            }
            
        except Exception as e:
            logger.error(f"Erro na an√°lise de inten√ß√£o: {e}")
            return {
                "intent": "geral",
                "confidence": 0.5,
                "message": message
            }
    
    def get_stats(self) -> Dict:
        """Retorna estat√≠sticas do servi√ßo"""
        stats = {
            "redis_connected": self.redis_client is not None,
            "memory_cache_size": len(self.memory_cache),
            "default_model": self.default_model
        }
        
        if self.redis_client:
            try:
                info = self.redis_client.info()
                stats["redis_memory"] = info.get("used_memory_human", "N/A")
                stats["redis_keys"] = self.redis_client.dbsize()
            except:
                pass
        
        return stats

# Inst√¢ncia global do servi√ßo
openai_service = OpenAIService()

